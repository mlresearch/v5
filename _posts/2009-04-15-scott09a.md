---
title: 'Novelty detection: Unlabeled data definitely help'
abstract: In machine learning, one formulation of the novelty detection problem is  to
  build a detector based on a training sample consisting of only nominal  data. The
  standard (inductive) approach to this problem has been to  declare novelties where
  the nominal density is low, which reduces the  problem to density level set estimation.
  In this paper, we consider the  setting where an unlabeled and possibly contaminated
  sample is also  available at learning time. We argue that novelty detection is naturally  solved
  by a general reduction to a binary classification problem. In  particular, a detector
  with a desired false positive rate can be achieved  through a reduction to Neyman-Pearson
  classification. Unlike the inductive  approach, our approach yields detectors that
  are optimal (e.g.,  statistically consistent) regardless of the distribution on
  novelties.  Therefore, in novelty detection, unlabeled data have a substantial impact  on
  the theoretical properties of the decision rule.
pdf: http://proceedings.pmlr.press/v/scott09a/scott09a.pdf
layout: inproceedings
id: scott09a
month: 0
firstpage: 464
lastpage: 471
page: 464-471
origpdf: http://jmlr.org/proceedings/papers/v5/scott09a/scott09a.pdf
sections: 
author:
- given: Clayton
  family: Scott
- given: Gilles
  family: Blanchard
date: 2009-04-15
address: Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA
publisher: PMLR
container-title: Proceedings of the Twelth International Conference on Artificial
  Intelligence and Statistics
volume: '5'
genre: inproceedings
issued:
  date-parts:
  - 2009
  - 4
  - 15
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
