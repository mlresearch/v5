---
title: Sleeping Experts and Bandits with Stochastic Action Availability and Adversarial
  Rewards
abstract: We consider algorithms for selecting actions in order to maximize rewards
  chosen by an adversary, where the set of actions available on any given round is
  selected stochastically. We present the first polynomial-time no-regret algorithms
  for this setting. In the full-observation (experts) version of the problem, we present
  an exponential-weights algorithm that  achieves regret O(\sqrt{T log n}), which
  is the best possible. For the bandit setting (where the algorithm only observes
  the reward of the action selected), we present a no-regret algorithm based on follow-the-perturbed-leader.
  This algorithm runs in polynomial time, unlike the EXP4 algorithm which can also
  be applied to this setting. Our algorithm has the interesting interpretation of
  solving a geometric experts problem where the embedding in which rewards are linear
  is never explicitly constructed. We argue that this adversarial-reward, stochastic
  availability formulation is important in practice, as assuming stationary stochastic
  rewards is unrealistic in many domains.
pdf: "./kanade09a/kanade09a.pdf"
layout: inproceedings
key: kanade09a
month: 0
firstpage: 272
lastpage: 279
origpdf: http://jmlr.org/proceedings/papers/v5/kanade09a/kanade09a.pdf
sections: 
authors:
- given: Varun
  family: Kanade
- given: H. Brendan
  family: McMahan
- given: Brent
  family: Bryan
---
