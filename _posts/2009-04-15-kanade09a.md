---
title: Sleeping Experts and Bandits with Stochastic Action Availability and Adversarial
  Rewards
abstract: We consider algorithms for selecting actions in order to maximize rewards
  chosen by an adversary, where the set of actions available on any given round is
  selected stochastically. We present the first polynomial-time no-regret algorithms
  for this setting. In the full-observation (experts) version of the problem, we present
  an exponential-weights algorithm that  achieves regret O(\sqrtT log n), which is
  the best possible. For the bandit setting (where the algorithm only observes the
  reward of the action selected), we present a no-regret algorithm based on follow-the-perturbed-leader.
  This algorithm runs in polynomial time, unlike the EXP4 algorithm which can also
  be applied to this setting. Our algorithm has the interesting interpretation of
  solving a geometric experts problem where the embedding in which rewards are linear
  is never explicitly constructed. We argue that this adversarial-reward, stochastic
  availability formulation is important in practice, as assuming stationary stochastic
  rewards is unrealistic in many domains.
pdf: http://jmlr.org/proceedings/papers/v5/kanade09a/kanade09a.pdf
layout: inproceedings
id: kanade09a
month: 0
firstpage: 272
lastpage: 279
page: 272-279
sections: 
author:
- given: Varun
  family: Kanade
- given: H. Brendan
  family: McMahan
- given: Brent
  family: Bryan
reponame: v5
date: 2009-04-15
address: Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA
publisher: PMLR
container-title: Proceedings of the Twelth International Conference on Artificial
  Intelligence and Statistics
volume: '5'
genre: inproceedings
issued:
  date-parts:
  - 2009
  - 4
  - 15
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
