---
title: An Expectation Maximization Algorithm for Continuous Markov Decision Processes
  with Arbitrary Reward
abstract: We derive a new expectation maximization algorithm for policy optimization
  in  linear Gaussian Markov decision processes, where the reward function is  parameterised
  in terms of a flexible mixture of Gaussians. This approach  exploits both analytical
  tractability and numerical optimization. Consequently,  on the one hand, it is more
  flexible and general than closed-form solutions,  such as the widely used linear
  quadratic Gaussian (LQG) controllers. On the  other hand, it is more accurate and
  faster than optimization methods that rely  on approximation and simulation. Partial
  analytical solutions (though costly)  eliminate the need for simulation and, hence,
  avoid approximation error. The  experiments will show that for the same cost of
  computation, policy  optimization methods that rely on analytical tractability have
  higher value  than the ones that rely on simulation.
pdf: http://proceedings.mlr.press/v5/hoffman09a/hoffman09a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hoffman09a
month: 0
firstpage: 232
lastpage: 239
page: 232-239
sections: 
author:
- given: Matthew
  family: Hoffman
- given: Nando
  family: Freitas
- given: Arnaud
  family: Doucet
- given: Jan
  family: Peters
date: 2009-04-15
address: Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA
publisher: PMLR
container-title: Proceedings of the Twelth International Conference on Artificial
  Intelligence and Statistics
volume: '5'
genre: inproceedings
issued:
  date-parts:
  - 2009
  - 4
  - 15
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
